{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "30323b2e84d84ba281f5d38eb1711ce5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_068c9fc337ec42b384eab45324de9e68",
              "IPY_MODEL_92b90dc1513e4151a53f3541a6139b89",
              "IPY_MODEL_59a2555a6ce84a358b62bbd105e02039"
            ],
            "layout": "IPY_MODEL_df7dec391a794192bd2e2064ba8c083c"
          }
        },
        "068c9fc337ec42b384eab45324de9e68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ea0263c4afd4d49940895d36d081f07",
            "placeholder": "​",
            "style": "IPY_MODEL_f36d445e092b4783ae63836867ccecc7",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "92b90dc1513e4151a53f3541a6139b89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_370aac888f92444c931d2a5b54842b07",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73616600a85c42ccb460eefefd0e2647",
            "value": 48
          }
        },
        "59a2555a6ce84a358b62bbd105e02039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc6e93b08f454202962a3c2072e45f64",
            "placeholder": "​",
            "style": "IPY_MODEL_7c3f5676c69540d28cfca0e5dd26fa39",
            "value": " 48.0/48.0 [00:00&lt;00:00, 1.54kB/s]"
          }
        },
        "df7dec391a794192bd2e2064ba8c083c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ea0263c4afd4d49940895d36d081f07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f36d445e092b4783ae63836867ccecc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "370aac888f92444c931d2a5b54842b07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73616600a85c42ccb460eefefd0e2647": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc6e93b08f454202962a3c2072e45f64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c3f5676c69540d28cfca0e5dd26fa39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2268400416a44a98214334c176d186c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7b08ec217e142faa970cc5c22783ee6",
              "IPY_MODEL_fa4c7f7323d3407b876b55f31060afa6",
              "IPY_MODEL_f485aafc1a614766a266981b470c8a61"
            ],
            "layout": "IPY_MODEL_0fc196d6575c4d79a712b32029299438"
          }
        },
        "a7b08ec217e142faa970cc5c22783ee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b4fd0f25a704ca9bb3a2756c381811f",
            "placeholder": "​",
            "style": "IPY_MODEL_183a7a75bfbb4475a15b06c56ffa3d9e",
            "value": "vocab.txt: 100%"
          }
        },
        "fa4c7f7323d3407b876b55f31060afa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1c2fc7bf7d24d0eab890967f7dc46d6",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02bc86e8b0a742508714d05ec6ff4a99",
            "value": 231508
          }
        },
        "f485aafc1a614766a266981b470c8a61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d37c6a004a76422d885c9676a6a50e81",
            "placeholder": "​",
            "style": "IPY_MODEL_bf5c431faf9947a990cc73ada08fd7f3",
            "value": " 232k/232k [00:00&lt;00:00, 2.61MB/s]"
          }
        },
        "0fc196d6575c4d79a712b32029299438": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b4fd0f25a704ca9bb3a2756c381811f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "183a7a75bfbb4475a15b06c56ffa3d9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1c2fc7bf7d24d0eab890967f7dc46d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02bc86e8b0a742508714d05ec6ff4a99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d37c6a004a76422d885c9676a6a50e81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf5c431faf9947a990cc73ada08fd7f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "422b2581f84d43b799a0a428539749a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d41cb0064b04e8fb99946ca0c060732",
              "IPY_MODEL_f8c94617f7a44b778e63ed0972e27758",
              "IPY_MODEL_bc01b4f3c0a9444285255c916d16d0af"
            ],
            "layout": "IPY_MODEL_67dedff201d1465a825e17b82331e55c"
          }
        },
        "4d41cb0064b04e8fb99946ca0c060732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a98d92025fb433592d8e3e8420b75a2",
            "placeholder": "​",
            "style": "IPY_MODEL_8ddfe03d5d224837b68aabd7393903b5",
            "value": "tokenizer.json: 100%"
          }
        },
        "f8c94617f7a44b778e63ed0972e27758": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_601bfb5b2fd64f608b218d802adda06c",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc5f542d4da2469da6b055b4a152d7eb",
            "value": 466062
          }
        },
        "bc01b4f3c0a9444285255c916d16d0af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60a4581e20d64892b23cc34ca1acbda4",
            "placeholder": "​",
            "style": "IPY_MODEL_e81fc816719d44a2b352fda09c5bfd57",
            "value": " 466k/466k [00:00&lt;00:00, 10.3MB/s]"
          }
        },
        "67dedff201d1465a825e17b82331e55c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a98d92025fb433592d8e3e8420b75a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ddfe03d5d224837b68aabd7393903b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "601bfb5b2fd64f608b218d802adda06c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc5f542d4da2469da6b055b4a152d7eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60a4581e20d64892b23cc34ca1acbda4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e81fc816719d44a2b352fda09c5bfd57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a350ae2fb5494650b4c516a73ac86146": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e716d291ac8d49a1b259610cb2a6b681",
              "IPY_MODEL_9f958ed59ced4dd5afc5694248cee2c0",
              "IPY_MODEL_4e61a133696947ab9191be08399c5a1d"
            ],
            "layout": "IPY_MODEL_eaafd63025f74a768a1420528bb5277c"
          }
        },
        "e716d291ac8d49a1b259610cb2a6b681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c846eced22b42f980c73c21ae01c638",
            "placeholder": "​",
            "style": "IPY_MODEL_744d5b079366408d8ef55c15de9b891b",
            "value": "config.json: 100%"
          }
        },
        "9f958ed59ced4dd5afc5694248cee2c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cbcce8a54e843dab18c0d02f8338fce",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_85e0f9fa44174bd9b5719cbd3ed74ffe",
            "value": 570
          }
        },
        "4e61a133696947ab9191be08399c5a1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37ebcec5c6684abd96788bdccdee45ad",
            "placeholder": "​",
            "style": "IPY_MODEL_2018a457fea04f12a5ec64cd1a240992",
            "value": " 570/570 [00:00&lt;00:00, 11.6kB/s]"
          }
        },
        "eaafd63025f74a768a1420528bb5277c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c846eced22b42f980c73c21ae01c638": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "744d5b079366408d8ef55c15de9b891b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3cbcce8a54e843dab18c0d02f8338fce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85e0f9fa44174bd9b5719cbd3ed74ffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "37ebcec5c6684abd96788bdccdee45ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2018a457fea04f12a5ec64cd1a240992": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d51fa5c744f40faa76fc102a1b2f41f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f05f8fde51ac43208d59a04b9ded4a11",
              "IPY_MODEL_2a8143943adc40389ad0b265eb25e8c4",
              "IPY_MODEL_12896e63a81a4d3ca5c735b3fe850038"
            ],
            "layout": "IPY_MODEL_5735132e93234c0f8039d91eb64724b5"
          }
        },
        "f05f8fde51ac43208d59a04b9ded4a11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b31cdfd39ce46cca2e38ba5276a2b7b",
            "placeholder": "​",
            "style": "IPY_MODEL_ab57da65dc934b2d9796ec0e3750a8dd",
            "value": "model.safetensors: 100%"
          }
        },
        "2a8143943adc40389ad0b265eb25e8c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca470f8a18db4014b29539926df00cdb",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd41d3215e2b46799293413bebf37237",
            "value": 440449768
          }
        },
        "12896e63a81a4d3ca5c735b3fe850038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1e69e944ce24afc8a5ed5d307453fe2",
            "placeholder": "​",
            "style": "IPY_MODEL_aa1984256d6643698d3416073a41040c",
            "value": " 440M/440M [00:04&lt;00:00, 125MB/s]"
          }
        },
        "5735132e93234c0f8039d91eb64724b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b31cdfd39ce46cca2e38ba5276a2b7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab57da65dc934b2d9796ec0e3750a8dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca470f8a18db4014b29539926df00cdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd41d3215e2b46799293413bebf37237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1e69e944ce24afc8a5ed5d307453fe2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa1984256d6643698d3416073a41040c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-oq8AO-L4_i",
        "outputId": "342be5c6-e8a0-423f-f23e-7ad47a2bf243"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "debug = False\n",
        "debug2 = False"
      ],
      "metadata": {
        "id": "291Bi-TWMSGZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import transformers\n",
        "import random\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "dp7L48eYLLO9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_seed(SEED):\n",
        "\n",
        "    random.seed(SEED)\n",
        "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "SEED = 508\n",
        "random_seed(SEED)"
      ],
      "metadata": {
        "id": "H6ZTa1IbLPS6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/sample_data/sentiment_tweets3.csv')\n",
        "display(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "0nWtYlZYMkod",
        "outputId": "f753dfbf-2bac-4e5a-ca4d-c893ae4decd5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        Index                                 message to examine  \\\n",
              "0         106  just had a real good moment. i missssssssss hi...   \n",
              "1         217         is reading manga  http://plurk.com/p/mzp1e   \n",
              "2         220  @comeagainjen http://twitpic.com/2y2lx - http:...   \n",
              "3         288  @lapcat Need to send 'em to my accountant tomo...   \n",
              "4         540      ADD ME ON MYSPACE!!!  myspace.com/LookThunder   \n",
              "...       ...                                                ...   \n",
              "10309  802309  No Depression by G Herbo is my mood from now o...   \n",
              "10310  802310  What do you do when depression succumbs the br...   \n",
              "10311  802311  Ketamine Nasal Spray Shows Promise Against Dep...   \n",
              "10312  802312  dont mistake a bad day with depression! everyo...   \n",
              "10313  802313                                                  0   \n",
              "\n",
              "       label (depression result)  \n",
              "0                              0  \n",
              "1                              0  \n",
              "2                              0  \n",
              "3                              0  \n",
              "4                              0  \n",
              "...                          ...  \n",
              "10309                          1  \n",
              "10310                          1  \n",
              "10311                          1  \n",
              "10312                          1  \n",
              "10313                          1  \n",
              "\n",
              "[10314 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dcc57850-d460-4d3e-bce6-e2a3e2c39dcf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Index</th>\n",
              "      <th>message to examine</th>\n",
              "      <th>label (depression result)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>106</td>\n",
              "      <td>just had a real good moment. i missssssssss hi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>217</td>\n",
              "      <td>is reading manga  http://plurk.com/p/mzp1e</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>220</td>\n",
              "      <td>@comeagainjen http://twitpic.com/2y2lx - http:...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>288</td>\n",
              "      <td>@lapcat Need to send 'em to my accountant tomo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>540</td>\n",
              "      <td>ADD ME ON MYSPACE!!!  myspace.com/LookThunder</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10309</th>\n",
              "      <td>802309</td>\n",
              "      <td>No Depression by G Herbo is my mood from now o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10310</th>\n",
              "      <td>802310</td>\n",
              "      <td>What do you do when depression succumbs the br...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10311</th>\n",
              "      <td>802311</td>\n",
              "      <td>Ketamine Nasal Spray Shows Promise Against Dep...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10312</th>\n",
              "      <td>802312</td>\n",
              "      <td>dont mistake a bad day with depression! everyo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10313</th>\n",
              "      <td>802313</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10314 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dcc57850-d460-4d3e-bce6-e2a3e2c39dcf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dcc57850-d460-4d3e-bce6-e2a3e2c39dcf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dcc57850-d460-4d3e-bce6-e2a3e2c39dcf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ab2eb673-cbc8-4f1c-a0ac-fb2cde8f1f49\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ab2eb673-cbc8-4f1c-a0ac-fb2cde8f1f49')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ab2eb673-cbc8-4f1c-a0ac-fb2cde8f1f49 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_b42291ea-4861-4814-a157-493501c7d26d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b42291ea-4861-4814-a157-493501c7d26d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 10314,\n  \"fields\": [\n    {\n      \"column\": \"Index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 261688,\n        \"min\": 106,\n        \"max\": 802313,\n        \"num_unique_values\": 10314,\n        \"samples\": [\n          251196,\n          504883,\n          787069\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"message to examine\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10282,\n        \"samples\": [\n          \"@Thorpeland No signal is the message that comes up on most monitors here when it's on but has no source. \",\n          \"1. The emotional ride of #perimenopause is ROUGH. I woke up fine, but then felt anger, irritation, just a feeling of wanting to break out, then fell down into a pit of depression. Man, the depression is frustrating and it definitely feels hormonal. I've been working on nutrition.\",\n          \"@dean2105 Stress-free is the way to be \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label (depression result)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns=['idx','text','label']\n",
        "N=list(range(len(data)))\n",
        "random.seed(2023)\n",
        "random.shuffle(N)\n",
        "data=data.iloc[N[0:5000]]\n",
        "class_names=['not depressed','depressed']"
      ],
      "metadata": {
        "id": "2WNp_-kFLzv4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(data, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "cGR-E6ZkNNQm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "30323b2e84d84ba281f5d38eb1711ce5",
            "068c9fc337ec42b384eab45324de9e68",
            "92b90dc1513e4151a53f3541a6139b89",
            "59a2555a6ce84a358b62bbd105e02039",
            "df7dec391a794192bd2e2064ba8c083c",
            "2ea0263c4afd4d49940895d36d081f07",
            "f36d445e092b4783ae63836867ccecc7",
            "370aac888f92444c931d2a5b54842b07",
            "73616600a85c42ccb460eefefd0e2647",
            "fc6e93b08f454202962a3c2072e45f64",
            "7c3f5676c69540d28cfca0e5dd26fa39",
            "a2268400416a44a98214334c176d186c",
            "a7b08ec217e142faa970cc5c22783ee6",
            "fa4c7f7323d3407b876b55f31060afa6",
            "f485aafc1a614766a266981b470c8a61",
            "0fc196d6575c4d79a712b32029299438",
            "2b4fd0f25a704ca9bb3a2756c381811f",
            "183a7a75bfbb4475a15b06c56ffa3d9e",
            "e1c2fc7bf7d24d0eab890967f7dc46d6",
            "02bc86e8b0a742508714d05ec6ff4a99",
            "d37c6a004a76422d885c9676a6a50e81",
            "bf5c431faf9947a990cc73ada08fd7f3",
            "422b2581f84d43b799a0a428539749a1",
            "4d41cb0064b04e8fb99946ca0c060732",
            "f8c94617f7a44b778e63ed0972e27758",
            "bc01b4f3c0a9444285255c916d16d0af",
            "67dedff201d1465a825e17b82331e55c",
            "4a98d92025fb433592d8e3e8420b75a2",
            "8ddfe03d5d224837b68aabd7393903b5",
            "601bfb5b2fd64f608b218d802adda06c",
            "fc5f542d4da2469da6b055b4a152d7eb",
            "60a4581e20d64892b23cc34ca1acbda4",
            "e81fc816719d44a2b352fda09c5bfd57",
            "a350ae2fb5494650b4c516a73ac86146",
            "e716d291ac8d49a1b259610cb2a6b681",
            "9f958ed59ced4dd5afc5694248cee2c0",
            "4e61a133696947ab9191be08399c5a1d",
            "eaafd63025f74a768a1420528bb5277c",
            "8c846eced22b42f980c73c21ae01c638",
            "744d5b079366408d8ef55c15de9b891b",
            "3cbcce8a54e843dab18c0d02f8338fce",
            "85e0f9fa44174bd9b5719cbd3ed74ffe",
            "37ebcec5c6684abd96788bdccdee45ad",
            "2018a457fea04f12a5ec64cd1a240992"
          ]
        },
        "id": "2OeNLyXuNSm9",
        "outputId": "6cb878bd-869a-4951-e313-44436bbbcd84"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30323b2e84d84ba281f5d38eb1711ce5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2268400416a44a98214334c176d186c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "422b2581f84d43b799a0a428539749a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a350ae2fb5494650b4c516a73ac86146"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#result of one sentence\n",
        "test_s = train[\"text\"].iloc[0]\n",
        "print(test_s)\n",
        "print()\n",
        "result1 = tokenizer.encode_plus(test_s)\n",
        "print(result1)\n",
        "print()\n",
        "print(tokenizer.decode(result1[\"input_ids\"]))\n",
        "print()\n",
        "len(test_s.split(\" \"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbDJFzB5NXsO",
        "outputId": "761b274d-c65b-40e7-d9c1-2279a689b373"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@jaychasm i wish i was there with you niggies! gnite luv! \n",
            "\n",
            "{'input_ids': [101, 1030, 6108, 7507, 6491, 1045, 4299, 1045, 2001, 2045, 2007, 2017, 9152, 13871, 3111, 999, 1043, 3490, 2618, 11320, 2615, 999, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "\n",
            "[CLS] @ jaychasm i wish i was there with you niggies! gnite luv! [SEP]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_sens = 16\n",
        "\n",
        "train = train.sort_values('label').reset_index(drop=True)\n",
        "train[\"kfold\"] = train.index % 5\n",
        "p_train = train[train[\"kfold\"]!=0].reset_index(drop=True)#1,2,3,4\n",
        "p_valid = train[train[\"kfold\"]==0].reset_index(drop=True)#0"
      ],
      "metadata": {
        "id": "FqJludKgNbIM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_test = test.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "tVxQPRhLNeVG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTDataSet(Dataset):\n",
        "\n",
        "    def __init__(self,sentences,targets):\n",
        "        self.sentences = sentences\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        sentence = self.sentences[idx]\n",
        "        bert_sens = tokenizer.encode_plus(\n",
        "                                sentence,\n",
        "                                add_special_tokens = True,\n",
        "                                max_length = max_sens,\n",
        "                                pad_to_max_length = True,\n",
        "                                return_attention_mask = True)\n",
        "\n",
        "        ids = torch.tensor(bert_sens['input_ids'], dtype=torch.long)\n",
        "        mask = torch.tensor(bert_sens['attention_mask'], dtype=torch.long)\n",
        "        token_type_ids = torch.tensor(bert_sens['token_type_ids'], dtype=torch.long)\n",
        "        target = torch.tensor(self.targets[idx],dtype=torch.float)\n",
        "\n",
        "        return {\n",
        "                'ids': ids,\n",
        "                'mask': mask,\n",
        "                'token_type_ids': token_type_ids,\n",
        "                'targets': target\n",
        "            }"
      ],
      "metadata": {
        "id": "wqtn4q1vNhDq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = BERTDataSet(p_train[\"text\"],p_train['label'])\n",
        "valid_dataset = BERTDataSet(p_valid[\"text\"],p_valid['label'])\n",
        "\n",
        "batch = 16\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset,batch_size=batch,shuffle = True,num_workers=8,pin_memory=True)\n",
        "valid_dataloader = DataLoader(valid_dataset,batch_size=batch,shuffle = False,num_workers=8,pin_memory=True)"
      ],
      "metadata": {
        "id": "p1Lc7f2HNmyq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = BERTDataSet(p_test[\"text\"],p_test['label'])\n",
        "test_dataloader = DataLoader(test_dataset,batch_size=batch,shuffle = False,num_workers=8,pin_memory=True)"
      ],
      "metadata": {
        "id": "W4e8KNrWNqDN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = transformers.BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels=1)\n",
        "#model = transformers.BertForSequenceClassification.from_pretrained(\"../input/bert-base-uncased\",num_labels=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142,
          "referenced_widgets": [
            "2d51fa5c744f40faa76fc102a1b2f41f",
            "f05f8fde51ac43208d59a04b9ded4a11",
            "2a8143943adc40389ad0b265eb25e8c4",
            "12896e63a81a4d3ca5c735b3fe850038",
            "5735132e93234c0f8039d91eb64724b5",
            "2b31cdfd39ce46cca2e38ba5276a2b7b",
            "ab57da65dc934b2d9796ec0e3750a8dd",
            "ca470f8a18db4014b29539926df00cdb",
            "bd41d3215e2b46799293413bebf37237",
            "a1e69e944ce24afc8a5ed5d307453fe2",
            "aa1984256d6643698d3416073a41040c"
          ]
        },
        "id": "CcCxijrHNssS",
        "outputId": "02bcdb06-bd3c-4f70-9eb4-b48cdea68ea2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d51fa5c744f40faa76fc102a1b2f41f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "model.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8yzZPF2Nwnu",
        "outputId": "d56b0762-91a6-4d66-e7cf-11c613dc4d38"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for item in train_dataloader:\n",
        "    ids = item[\"ids\"].to(device)\n",
        "    mask = item[\"mask\"].to(device)\n",
        "    #tokentype = a[\"token_type_ids\"].to(device)\n",
        "    output = model(ids,mask)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvk0l5B2N2nr",
        "outputId": "d5649462-474b-4bce-d548-bd870e44904b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = output[\"logits\"].squeeze(-1).shape"
      ],
      "metadata": {
        "id": "3xnXcMzyN5iV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "60qxfgMZpuWt"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "LR=2e-5\n",
        "optimizer = AdamW(model.parameters(), LR,betas=(0.9, 0.999), weight_decay=1e-2)"
      ],
      "metadata": {
        "id": "zhLN8oZ1N-Cq"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs = 20\n",
        "if debug:\n",
        "    epochs = 1\n",
        "train_steps = int(len(p_train)/batch*epochs)\n",
        "print(train_steps)\n",
        "num_steps = int(train_steps*0.1)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d6Oq1Y3OAn1",
        "outputId": "2bd6005a-ddcd-4137-8036-f366415064ad"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(output,target):\n",
        "    return torch.sqrt(nn.MSELoss()(output,target))"
      ],
      "metadata": {
        "id": "tFtfTnJEOE4q"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n"
      ],
      "metadata": {
        "id": "vf93GYMSxot2"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training(\n",
        "    train_dataloader,\n",
        "    model,\n",
        "    optimizer,\n",
        "    scheduler\n",
        "):\n",
        "\n",
        "    model.train()\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    allpreds = []\n",
        "    alltargets = []\n",
        "\n",
        "    for a in train_dataloader:\n",
        "        losses = []\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            ids = a[\"ids\"].to(device,non_blocking=True)\n",
        "            mask = a[\"mask\"].to(device,non_blocking=True)\n",
        "            tokentype = a[\"token_type_ids\"].to(device,non_blocking=True)\n",
        "            output = model(ids,mask)\n",
        "            output = output[\"logits\"].squeeze(-1)\n",
        "            target = a[\"targets\"].to(device,non_blocking=True)\n",
        "            loss = loss_fn(output,target)\n",
        "            losses.append(loss.item())\n",
        "            allpreds.append(output.detach().cpu().numpy())\n",
        "            alltargets.append(target.detach().squeeze(-1).cpu().numpy())\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        del loss\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    allpreds = np.concatenate(allpreds)\n",
        "    alltargets = np.concatenate(alltargets)\n",
        "    losses = np.mean(losses)\n",
        "    # Score with rmse\n",
        "    train_rme_loss = np.sqrt(mean_squared_error(alltargets,allpreds))\n",
        "\n",
        "    return losses,train_rme_loss\n",
        "\n",
        "\n",
        "# def training(train_dataloader, model, optimizer, scheduler, use_amp=True):\n",
        "#     model.train()\n",
        "#     allpreds = []\n",
        "#     alltargets = []\n",
        "#     losses = []\n",
        "\n",
        "#     for a in train_dataloader:\n",
        "#         optimizer.zero_grad()\n",
        "\n",
        "#         if use_amp:\n",
        "#             with torch.cuda.amp.autocast():\n",
        "#                 ids = a[\"ids\"].to(device, non_blocking=True)\n",
        "#                 mask = a[\"mask\"].to(device, non_blocking=True)\n",
        "#                 output = model(ids, mask)[\"logits\"].squeeze(-1)\n",
        "#                 target = a[\"targets\"].to(device, non_blocking=True)\n",
        "#                 loss = loss_fn(output, target)\n",
        "#         else:\n",
        "#             ids = a[\"ids\"].to(device, non_blocking=True)\n",
        "#             mask = a[\"mask\"].to(device, non_blocking=True)\n",
        "#             output = model(ids, mask)[\"logits\"].squeeze(-1)\n",
        "#             target = a[\"targets\"].to(device, non_blocking=True)\n",
        "#             loss = loss_fn(output, target)\n",
        "\n",
        "#         losses.append(loss.item())\n",
        "#         allpreds.append(output.detach().cpu().numpy())\n",
        "#         alltargets.append(target.detach().squeeze(-1).cpu().numpy())\n",
        "\n",
        "#         if use_amp:\n",
        "#             scaler.scale(loss).backward()\n",
        "#             scaler.step(optimizer)\n",
        "#             scaler.update()\n",
        "#         else:\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "\n",
        "#         if scheduler:\n",
        "#             scheduler.step()\n",
        "\n",
        "#     allpreds = np.concatenate(allpreds)\n",
        "#     alltargets = np.concatenate(alltargets)\n",
        "#     avg_loss = np.mean(losses)\n",
        "#     rmse = np.sqrt(mean_squared_error(alltargets, allpreds))\n",
        "\n",
        "#     return avg_loss, rmse\n"
      ],
      "metadata": {
        "id": "Td9lkqR5OF2r"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validating(\n",
        "    valid_dataloader,\n",
        "    model\n",
        "):\n",
        "\n",
        "    model.eval()\n",
        "    allpreds = []\n",
        "    alltargets = []\n",
        "\n",
        "    for a in valid_dataloader:\n",
        "        losses = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            ids = a[\"ids\"].to(device)\n",
        "            mask = a[\"mask\"].to(device)\n",
        "            tokentype = a[\"token_type_ids\"].to(device)\n",
        "            output = model(ids,mask)\n",
        "            output = output[\"logits\"].squeeze(-1)\n",
        "            target = a[\"targets\"].to(device)\n",
        "            loss = loss_fn(output,target)\n",
        "            losses.append(loss.item())\n",
        "            allpreds.append(output.detach().cpu().numpy())\n",
        "            alltargets.append(target.detach().squeeze(-1).cpu().numpy())\n",
        "\n",
        "            del loss\n",
        "\n",
        "    allpreds = np.concatenate(allpreds)\n",
        "    alltargets = np.concatenate(alltargets)\n",
        "    losses = np.mean(losses)\n",
        "    valid_rme_loss = np.sqrt(mean_squared_error(alltargets,allpreds))\n",
        "\n",
        "    return allpreds,losses,valid_rme_loss\n"
      ],
      "metadata": {
        "id": "_FYcM4PbOMPg"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if debug2 == False:\n",
        "    for a in range(epochs):\n",
        "        for b in train_dataloader:\n",
        "            break\n",
        "    losses,train_rme_loss = training(train_dataloader,model,optimizer,scheduler)\n",
        "\n",
        "    for a in valid_dataloader:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjOZukUQORbM",
        "outputId": "cadc413c-ca16-4519-b457-67345c1203ec"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initializing the data\n",
        "p_train = train[train[\"kfold\"]!=0].reset_index(drop=True)\n",
        "p_valid = train[train[\"kfold\"]==0].reset_index(drop=True)\n",
        "\n",
        "train_dataset = BERTDataSet(p_train[\"text\"],p_train['label'])\n",
        "valid_dataset = BERTDataSet(p_valid[\"text\"],p_valid['label'])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset,batch_size=batch,shuffle = True,num_workers=4,pin_memory=True)\n",
        "valid_dataloader = DataLoader(valid_dataset,batch_size=batch,shuffle = False,num_workers=4,pin_memory=True)\n",
        "\n",
        "model = transformers.BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels=1)\n",
        "\n",
        "model.to(device)\n",
        "LR=2e-5\n",
        "optimizer = AdamW(model.parameters(), LR,betas=(0.9, 0.999), weight_decay=1e-2) # AdamW optimizer\n",
        "\n",
        "train_steps = int(len(p_train)/batch*epochs)\n",
        "\n",
        "num_steps = int(train_steps*0.1)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVQTAZUTOWu3",
        "outputId": "07dcf35b-5d81-4a14-9e2e-10fc455b4db6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainlosses = []\n",
        "vallosses = []\n",
        "bestscore = None\n",
        "\n",
        "trainscores = []\n",
        "validscores = []\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    print()\n",
        "    print(\"epoch \" + str(epoch) + \" start -------------\")\n",
        "\n",
        "    trainloss,trainscore = training(train_dataloader,model,optimizer,scheduler)\n",
        "\n",
        "    trainlosses.append(trainloss)\n",
        "    trainscores.append(trainscore)\n",
        "\n",
        "    print(\"trainscore is \" + str(trainscore))\n",
        "\n",
        "    preds,validloss,valscore=validating(valid_dataloader,model)\n",
        "\n",
        "    vallosses.append(validloss)\n",
        "    validscores.append(valscore)\n",
        "\n",
        "    print(\"valscore is \" + str(valscore))\n",
        "\n",
        "    if bestscore is None:\n",
        "        bestscore = valscore\n",
        "\n",
        "        print(\"Save first model\")\n",
        "\n",
        "        state = {\n",
        "                        'state_dict': model.state_dict(),\n",
        "                        'optimizer_dict': optimizer.state_dict(),\n",
        "                        \"bestscore\":bestscore\n",
        "                    }\n",
        "\n",
        "        torch.save(state, \"model0.pth\")\n",
        "\n",
        "    elif bestscore > valscore:\n",
        "\n",
        "        bestscore = valscore\n",
        "        print(\"found better point\")\n",
        "        state = {\n",
        "                        'state_dict': model.state_dict(),\n",
        "                        'optimizer_dict': optimizer.state_dict(),\n",
        "                        \"bestscore\":bestscore\n",
        "                    }\n",
        "\n",
        "        torch.save(state, \"model0.pth\")\n",
        "\n",
        "    else:\n",
        "        pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSHuvHBlOfTf",
        "outputId": "2f992dd7-e51e-4613-ae93-29b2fc173fb0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch 0 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.4018109321249169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.2337285584162668\n",
            "Save first model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 1/20 [00:22<07:15, 22.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch 1 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.2503408254534254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.20283715320157164\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [00:48<07:23, 24.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch 2 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.19747598215325665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.18342836519725994\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 3/20 [01:15<07:16, 25.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch 3 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.14905962323465796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 20%|██        | 4/20 [01:32<05:56, 22.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.2021306900858367\n",
            "\n",
            "epoch 4 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.11611961735665766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 25%|██▌       | 5/20 [01:50<05:08, 20.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.20360140685806716\n",
            "\n",
            "epoch 5 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.0963831795580865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.17991206400363974\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 6/20 [02:12<04:56, 21.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch 6 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.07837955904721342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 35%|███▌      | 7/20 [02:30<04:19, 19.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.19221211136263075\n",
            "\n",
            "epoch 7 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.07905511021946368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 40%|████      | 8/20 [02:47<03:48, 19.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.2126029021387344\n",
            "\n",
            "epoch 8 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.07436120954756635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 45%|████▌     | 9/20 [03:04<03:24, 18.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.23292058445519281\n",
            "\n",
            "epoch 9 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.07100358724073869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 50%|█████     | 10/20 [03:22<03:03, 18.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.19686528931238556\n",
            "\n",
            "epoch 10 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.05725087692479815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 55%|█████▌    | 11/20 [03:40<02:42, 18.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.2025220983421463\n",
            "\n",
            "epoch 11 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.054235695257687476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 60%|██████    | 12/20 [03:57<02:22, 17.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.18120839364892946\n",
            "\n",
            "epoch 12 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.04882155612628871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 65%|██████▌   | 13/20 [04:14<02:03, 17.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.18205627956953918\n",
            "\n",
            "epoch 13 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.044413318304874376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 70%|███████   | 14/20 [04:32<01:45, 17.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.1868788643185457\n",
            "\n",
            "epoch 14 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.04415550297680939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 75%|███████▌  | 15/20 [04:49<01:27, 17.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.18401225055011441\n",
            "\n",
            "epoch 15 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.04400914113229703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 80%|████████  | 16/20 [05:07<01:10, 17.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.18682073696797977\n",
            "\n",
            "epoch 16 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.04348579938615511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 85%|████████▌ | 17/20 [05:25<00:53, 17.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.18685324704944883\n",
            "\n",
            "epoch 17 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.04280663518213313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 90%|█████████ | 18/20 [05:42<00:35, 17.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.18790638118037029\n",
            "\n",
            "epoch 18 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.04292087841378476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 95%|█████████▌| 19/20 [05:59<00:17, 17.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.18772687696198553\n",
            "\n",
            "epoch 19 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.04291020273562914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "100%|██████████| 20/20 [06:17<00:00, 18.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.1872211906638232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import time\n",
        "# import copy\n",
        "\n",
        "# def run_training(use_amp=True, label=\"AMP\"):\n",
        "#     # Reset model, optimizer, scheduler\n",
        "#     model = transformers.BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=1)\n",
        "#     model.to(device)\n",
        "\n",
        "#     optimizer = AdamW(model.parameters(), lr=2e-5, betas=(0.9, 0.999), weight_decay=1e-2)\n",
        "#     train_steps = int(len(p_train)/batch*epochs)\n",
        "#     num_steps = int(train_steps * 0.1)\n",
        "#     scheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)\n",
        "\n",
        "#     trainlosses = []\n",
        "#     vallosses = []\n",
        "#     trainscores = []\n",
        "#     validscores = []\n",
        "#     bestscore = None\n",
        "\n",
        "#     start_time = time.time()\n",
        "\n",
        "#     for epoch in tqdm(range(epochs)):\n",
        "#         print(f\"\\nEpoch {epoch} start ------------- [{label}]\")\n",
        "\n",
        "#         trainloss, trainscore = training(train_dataloader, model, optimizer, scheduler, use_amp=use_amp)\n",
        "#         trainlosses.append(trainloss)\n",
        "#         trainscores.append(trainscore)\n",
        "\n",
        "#         print(f\"Train score: {trainscore:.4f}\")\n",
        "\n",
        "#         preds, validloss, valscore = validating(valid_dataloader, model)\n",
        "#         vallosses.append(validloss)\n",
        "#         validscores.append(valscore)\n",
        "\n",
        "#         print(f\"Validation score: {valscore:.4f}\")\n",
        "\n",
        "#         if bestscore is None or bestscore > valscore:\n",
        "#             bestscore = valscore\n",
        "#             print(\"Saving new best model...\")\n",
        "#             state = {\n",
        "#                 'state_dict': model.state_dict(),\n",
        "#                 'optimizer_dict': optimizer.state_dict(),\n",
        "#                 \"bestscore\": bestscore\n",
        "#             }\n",
        "#             torch.save(state, f\"model_{label.lower()}.pth\")\n",
        "\n",
        "#     duration = time.time() - start_time\n",
        "\n",
        "#     print(f\"\\n[{label}] Total Training Time: {duration:.2f}s | Best Validation RMSE: {bestscore:.4f}\")\n",
        "#     return bestscore, duration\n",
        "\n",
        "\n",
        "# # Run both experiments\n",
        "# rmse_amp, duration_amp = run_training(use_amp=True, label=\"AMP\")\n",
        "# rmse_noamp, duration_noamp = run_training(use_amp=False, label=\"NoAMP\")\n",
        "\n",
        "# # Compare\n",
        "# print(\"\\n====== Summary ======\")\n",
        "# print(f\"AMP     - Time: {duration_amp:.2f}s, RMSE: {rmse_amp:.4f}\")\n",
        "# print(f\"No AMP  - Time: {duration_noamp:.2f}s, RMSE: {rmse_noamp:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ki1k3EyWyFeK",
        "outputId": "e2a21f97-d28b-44f7-d076-fd42c78e946a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 0 start ------------- [AMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.3551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.2267\n",
            "Saving new best model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 1/20 [00:30<09:41, 30.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1 start ------------- [AMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.2535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 10%|█         | 2/20 [00:47<06:48, 22.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.2295\n",
            "\n",
            "Epoch 2 start ------------- [AMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.2043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.1774\n",
            "Saving new best model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 3/20 [01:11<06:33, 23.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3 start ------------- [AMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.1501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 20%|██        | 4/20 [01:29<05:35, 20.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.1875\n",
            "\n",
            "Epoch 4 start ------------- [AMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.1262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 25%|██▌       | 5/20 [01:46<04:57, 19.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.1824\n",
            "\n",
            "Epoch 5 start ------------- [AMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.1081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 30%|███       | 6/20 [02:04<04:26, 19.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.1899\n",
            "\n",
            "Epoch 6 start ------------- [AMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.0921\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 35%|███▌      | 7/20 [02:22<04:03, 18.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.1953\n",
            "\n",
            "Epoch 7 start ------------- [AMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.0870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 40%|████      | 8/20 [02:40<03:40, 18.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.1940\n",
            "\n",
            "Epoch 8 start ------------- [AMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.0730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 45%|████▌     | 9/20 [02:57<03:19, 18.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.2179\n",
            "\n",
            "Epoch 9 start ------------- [AMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.0663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 50%|█████     | 10/20 [03:15<02:59, 17.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.1916\n",
            "\n",
            "Epoch 10 start ------------- [AMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.0626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 55%|█████▌    | 11/20 [03:32<02:38, 17.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.1923\n",
            "\n",
            "Epoch 11 start ------------- [AMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.0680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 60%|██████    | 12/20 [03:49<02:20, 17.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.1995\n",
            "\n",
            "Epoch 12 start ------------- [AMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.0580\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 65%|██████▌   | 13/20 [04:06<02:02, 17.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.1849\n",
            "\n",
            "Epoch 13 start ------------- [AMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.0554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 70%|███████   | 14/20 [04:24<01:44, 17.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.1823\n",
            "\n",
            "Epoch 14 start ------------- [AMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.0570\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 75%|███████▌  | 15/20 [04:41<01:27, 17.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.1817\n",
            "\n",
            "Epoch 15 start ------------- [AMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.0539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 80%|████████  | 16/20 [04:58<01:09, 17.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.1840\n",
            "\n",
            "Epoch 16 start ------------- [AMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.0530\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 85%|████████▌ | 17/20 [05:15<00:51, 17.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.1851\n",
            "\n",
            "Epoch 17 start ------------- [AMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.0509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 90%|█████████ | 18/20 [05:32<00:34, 17.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.1859\n",
            "\n",
            "Epoch 18 start ------------- [AMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.0509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 95%|█████████▌| 19/20 [05:50<00:17, 17.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.1827\n",
            "\n",
            "Epoch 19 start ------------- [AMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.0493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "100%|██████████| 20/20 [06:07<00:00, 18.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.1820\n",
            "\n",
            "[AMP] Total Training Time: 367.49s | Best Validation RMSE: 0.1774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 0 start ------------- [NoAMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.3785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.2372\n",
            "Saving new best model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 1/20 [00:23<07:22, 23.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1 start ------------- [NoAMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.2480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.1942\n",
            "Saving new best model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [00:46<07:01, 23.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2 start ------------- [NoAMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.2032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.1873\n",
            "Saving new best model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 3/20 [01:12<06:53, 24.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3 start ------------- [NoAMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.1578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 20%|██        | 4/20 [01:29<05:44, 21.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.2117\n",
            "\n",
            "Epoch 4 start ------------- [NoAMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.1174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 25%|██▌       | 5/20 [01:46<05:00, 20.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.2064\n",
            "\n",
            "Epoch 5 start ------------- [NoAMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 30%|███       | 6/20 [02:04<04:27, 19.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.1957\n",
            "\n",
            "Epoch 6 start ------------- [NoAMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.0959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.1735\n",
            "Saving new best model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 7/20 [02:29<04:34, 21.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7 start ------------- [NoAMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.0798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 40%|████      | 8/20 [02:47<04:01, 20.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.2007\n",
            "\n",
            "Epoch 8 start ------------- [NoAMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.0922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 45%|████▌     | 9/20 [03:04<03:32, 19.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.1919\n",
            "\n",
            "Epoch 9 start ------------- [NoAMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.0946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 50%|█████     | 10/20 [03:22<03:07, 18.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.1904\n",
            "\n",
            "Epoch 10 start ------------- [NoAMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.0737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 55%|█████▌    | 11/20 [03:39<02:44, 18.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.1946\n",
            "\n",
            "Epoch 11 start ------------- [NoAMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.0707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 60%|██████    | 12/20 [03:56<02:23, 17.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.1841\n",
            "\n",
            "Epoch 12 start ------------- [NoAMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.0657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 65%|██████▌   | 13/20 [04:14<02:05, 17.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.2004\n",
            "\n",
            "Epoch 13 start ------------- [NoAMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.0635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 70%|███████   | 14/20 [04:32<01:46, 17.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.1837\n",
            "\n",
            "Epoch 14 start ------------- [NoAMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.0626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 75%|███████▌  | 15/20 [04:49<01:28, 17.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.1875\n",
            "\n",
            "Epoch 15 start ------------- [NoAMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.0681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 80%|████████  | 16/20 [05:06<01:10, 17.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.1908\n",
            "\n",
            "Epoch 16 start ------------- [NoAMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.0579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 85%|████████▌ | 17/20 [05:23<00:52, 17.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.1818\n",
            "\n",
            "Epoch 17 start ------------- [NoAMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.0543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 90%|█████████ | 18/20 [05:41<00:35, 17.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.1865\n",
            "\n",
            "Epoch 18 start ------------- [NoAMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.0495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 95%|█████████▌| 19/20 [05:59<00:17, 17.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.1808\n",
            "\n",
            "Epoch 19 start ------------- [NoAMP]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train score: 0.0472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "100%|██████████| 20/20 [06:16<00:00, 18.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation score: 0.1808\n",
            "\n",
            "[NoAMP] Total Training Time: 376.43s | Best Validation RMSE: 0.1735\n",
            "\n",
            "====== Summary ======\n",
            "AMP     - Time: 367.49s, RMSE: 0.1774\n",
            "No AMP  - Time: 376.43s, RMSE: 0.1735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(p_valid['label'],preds, alpha=0.2)\n",
        "plt.title('Validation Prediction Result')\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Prediction')\n",
        "plt.show()\n",
        "\n",
        "x = np.arange(epochs)\n",
        "plt.title('Validation Losses')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(x,trainlosses)\n",
        "plt.plot(x,vallosses)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "wK_FhJYOOl16",
        "outputId": "cbccce24-4af3-4852-f283-8ea7560ba10e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.arange(epochs)\n",
        "plt.title('Validation Scores')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Score')\n",
        "plt.plot(x,trainscores)\n",
        "plt.plot(x,validscores)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "R0fB8IqnOo5J",
        "outputId": "c1f2f19e-725c-4dca-baca-98211faef6d2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names=['Not Depressed','Depressed']"
      ],
      "metadata": {
        "id": "oCdoLhUpOsUr"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_true = p_valid['label']\n",
        "val_pred = []\n",
        "for p in preds:\n",
        "    val_pred+=[np.where(p<0.5,0,1).item()]"
      ],
      "metadata": {
        "id": "KNjyqk6eOvHl"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FAWmswMRBH7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(val_true,val_pred,target_names=class_names,digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEMbXOVdOx6y",
        "outputId": "5960eb96-fa90-41f1-f3a3-2a86a49ec084"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "Not Depressed     0.9697    0.9791    0.9744       622\n",
            "    Depressed     0.9244    0.8933    0.9086       178\n",
            "\n",
            "     accuracy                         0.9600       800\n",
            "    macro avg     0.9471    0.9362    0.9415       800\n",
            " weighted avg     0.9597    0.9600    0.9598       800\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predicting(test_dataloader,model,):\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    allpreds = []\n",
        "    preds = []\n",
        "    allvalloss=0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for a in test_dataloader:\n",
        "\n",
        "            ids = a[\"ids\"].to(device)\n",
        "            mask = a[\"mask\"].to(device)\n",
        "            tokentype = a[\"token_type_ids\"].to(device)\n",
        "\n",
        "           # output = model(ids,mask,tokentype)\n",
        "            output = model(ids,mask)\n",
        "            output = output[\"logits\"].squeeze(-1)\n",
        "            preds.append(output.cpu().numpy())\n",
        "\n",
        "        preds = np.concatenate(preds)\n",
        "        allpreds.append(preds)\n",
        "\n",
        "    return allpreds\n"
      ],
      "metadata": {
        "id": "xacoZWwwO0o8"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tpreds = predicting(test_dataloader,model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJwYmkCLO5YO",
        "outputId": "dbf1a8f7-2739-44f0-da82-bc52dd77e1bd"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_true = p_test['label']\n",
        "test_pred = []\n",
        "for p in tpreds[0]:\n",
        "    test_pred+=[np.where(p<0.5,0,1).item()]\n",
        "\n",
        "#tpred_df = pd.DataFrame(tpreds)\n",
        "#tpred_dfT = tpred_df.T\n",
        "#test_pred = tpred_dfT.mean(axis=1)"
      ],
      "metadata": {
        "id": "ayyyym_9O8Jf"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test_true,test_pred,target_names=class_names,digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkK_vz9KPBLw",
        "outputId": "76c229a0-fb91-490b-dca4-2d8b73d5fa70"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "Not Depressed     0.9496    0.9729    0.9611       775\n",
            "    Depressed     0.8981    0.8222    0.8585       225\n",
            "\n",
            "     accuracy                         0.9390      1000\n",
            "    macro avg     0.9238    0.8976    0.9098      1000\n",
            " weighted avg     0.9380    0.9390    0.9380      1000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}