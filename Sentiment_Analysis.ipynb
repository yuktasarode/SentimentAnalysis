{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP17KxzNpth5cTXvKHwqxu4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "295d155ab8894ee4935db8fc8faa0af1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6fa7b065d05248d399a9d8d41ec27457",
              "IPY_MODEL_52f00db720c9442d878150a577d156d6",
              "IPY_MODEL_291f006d4df343908bae50ffc00ce933"
            ],
            "layout": "IPY_MODEL_e0b1c542376b461f94f2f519c2286730"
          }
        },
        "6fa7b065d05248d399a9d8d41ec27457": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d545192a3fe349b096caa94e9db1cc1f",
            "placeholder": "​",
            "style": "IPY_MODEL_897fda141a004332851330e5eb2bf4fc",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "52f00db720c9442d878150a577d156d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c739e3dd8384625875e195c7da85f55",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_618ec3af54fc435bb1b40beb298c9e0d",
            "value": 231508
          }
        },
        "291f006d4df343908bae50ffc00ce933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7996bf9809124ea7a25bfe295651de2c",
            "placeholder": "​",
            "style": "IPY_MODEL_ffad9bd2f7bb4a9a8a506fddb7377529",
            "value": " 232k/232k [00:00&lt;00:00, 3.90MB/s]"
          }
        },
        "e0b1c542376b461f94f2f519c2286730": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d545192a3fe349b096caa94e9db1cc1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "897fda141a004332851330e5eb2bf4fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c739e3dd8384625875e195c7da85f55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "618ec3af54fc435bb1b40beb298c9e0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7996bf9809124ea7a25bfe295651de2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffad9bd2f7bb4a9a8a506fddb7377529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe0ac8369fea42d4afc8cbe171251f8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e18f556ebd843cdbb4ed4d655f77b14",
              "IPY_MODEL_bda1ffa3277449b6a3aa09a32c035b10",
              "IPY_MODEL_e5311e4a617f472ab8e64b79f3419c9d"
            ],
            "layout": "IPY_MODEL_23fc794c6fd3450d8d1d4034fdb14ace"
          }
        },
        "2e18f556ebd843cdbb4ed4d655f77b14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46f7e823aa81473ca06c0f67066cde0f",
            "placeholder": "​",
            "style": "IPY_MODEL_66542b381eb14e5996f9ad560cb14179",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "bda1ffa3277449b6a3aa09a32c035b10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbc86fef959545b4b620480f7fd2b69e",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe7f7ce50785477b9f25c52ff9b6a7ca",
            "value": 28
          }
        },
        "e5311e4a617f472ab8e64b79f3419c9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab3a034d136649df8b5d35556d65cf23",
            "placeholder": "​",
            "style": "IPY_MODEL_211e755a40a54adab8261a79ee970ceb",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.73kB/s]"
          }
        },
        "23fc794c6fd3450d8d1d4034fdb14ace": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46f7e823aa81473ca06c0f67066cde0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66542b381eb14e5996f9ad560cb14179": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbc86fef959545b4b620480f7fd2b69e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe7f7ce50785477b9f25c52ff9b6a7ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab3a034d136649df8b5d35556d65cf23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "211e755a40a54adab8261a79ee970ceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da64abc61e12437bbf0c45892060a9ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f13280d8ed7345db90fc8a9485355e76",
              "IPY_MODEL_d520b1f6f1fd4394ac8e9962a559f859",
              "IPY_MODEL_2928320b745f4cdb8d65abf6b2dcbbc4"
            ],
            "layout": "IPY_MODEL_349cbf4b644a4e37a0ba87660a785fa4"
          }
        },
        "f13280d8ed7345db90fc8a9485355e76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3608cf560ab4f9c9d98c5960d1f07d2",
            "placeholder": "​",
            "style": "IPY_MODEL_4e82268e7be1458d9213c832a75a4512",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "d520b1f6f1fd4394ac8e9962a559f859": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa7c4e675c1942f494fa623d8cc91918",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de75ada89e024221a9e59a8c24ca5a8d",
            "value": 570
          }
        },
        "2928320b745f4cdb8d65abf6b2dcbbc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ebb3958724d4025bcfaf025b444937c",
            "placeholder": "​",
            "style": "IPY_MODEL_f57435ebaad0473096267f32e436dce3",
            "value": " 570/570 [00:00&lt;00:00, 44.8kB/s]"
          }
        },
        "349cbf4b644a4e37a0ba87660a785fa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3608cf560ab4f9c9d98c5960d1f07d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e82268e7be1458d9213c832a75a4512": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa7c4e675c1942f494fa623d8cc91918": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de75ada89e024221a9e59a8c24ca5a8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ebb3958724d4025bcfaf025b444937c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f57435ebaad0473096267f32e436dce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48144e0a6e474c54b20ad047771c0c04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_718b958f9d064f5eadcacc70fcb910ec",
              "IPY_MODEL_2e3e424819df4a9bb36371de16d60e07",
              "IPY_MODEL_da5f103e694746cb8eb00fb47dc11fd1"
            ],
            "layout": "IPY_MODEL_2f52acc35a2f4903ae142d300f260a3e"
          }
        },
        "718b958f9d064f5eadcacc70fcb910ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_915450a7ff924aae8c3ac34d6aa8ba99",
            "placeholder": "​",
            "style": "IPY_MODEL_8e1b74969658490faed6238acd740335",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "2e3e424819df4a9bb36371de16d60e07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb641373276c4e8e88d93973ab91893c",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_189eb38b743845cf85adbe4acc9f397d",
            "value": 440473133
          }
        },
        "da5f103e694746cb8eb00fb47dc11fd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_423b96cdd138492ebec9ea71cd4fd99f",
            "placeholder": "​",
            "style": "IPY_MODEL_5e8a2acfd68c43e78af50eefe418d850",
            "value": " 440M/440M [00:02&lt;00:00, 189MB/s]"
          }
        },
        "2f52acc35a2f4903ae142d300f260a3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "915450a7ff924aae8c3ac34d6aa8ba99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e1b74969658490faed6238acd740335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb641373276c4e8e88d93973ab91893c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "189eb38b743845cf85adbe4acc9f397d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "423b96cdd138492ebec9ea71cd4fd99f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e8a2acfd68c43e78af50eefe418d850": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuktasarode/SentimentAnalysis/blob/main/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-oq8AO-L4_i",
        "outputId": "8edc959c-1e06-44ba-b630-3304ac4cea32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.15.1 tokenizers-0.13.3 transformers-4.29.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "debug = False\n",
        "debug2 = False"
      ],
      "metadata": {
        "id": "291Bi-TWMSGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import transformers\n",
        "import random\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "dp7L48eYLLO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_seed(SEED):\n",
        "\n",
        "    random.seed(SEED)\n",
        "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "SEED = 508\n",
        "random_seed(SEED)"
      ],
      "metadata": {
        "id": "H6ZTa1IbLPS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/sample_data/sentiment_tweets3.csv')\n",
        "display(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "0nWtYlZYMkod",
        "outputId": "2674d77e-e011-475e-fbda-d637857a420c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        Index                                 message to examine  \\\n",
              "0         106  just had a real good moment. i missssssssss hi...   \n",
              "1         217         is reading manga  http://plurk.com/p/mzp1e   \n",
              "2         220  @comeagainjen http://twitpic.com/2y2lx - http:...   \n",
              "3         288  @lapcat Need to send 'em to my accountant tomo...   \n",
              "4         540      ADD ME ON MYSPACE!!!  myspace.com/LookThunder   \n",
              "...       ...                                                ...   \n",
              "10309  802309  No Depression by G Herbo is my mood from now o...   \n",
              "10310  802310  What do you do when depression succumbs the br...   \n",
              "10311  802311  Ketamine Nasal Spray Shows Promise Against Dep...   \n",
              "10312  802312  dont mistake a bad day with depression! everyo...   \n",
              "10313  802313                                                  0   \n",
              "\n",
              "       label (depression result)  \n",
              "0                              0  \n",
              "1                              0  \n",
              "2                              0  \n",
              "3                              0  \n",
              "4                              0  \n",
              "...                          ...  \n",
              "10309                          1  \n",
              "10310                          1  \n",
              "10311                          1  \n",
              "10312                          1  \n",
              "10313                          1  \n",
              "\n",
              "[10314 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-27c60ee8-6997-4b48-99a2-97c2137b4249\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Index</th>\n",
              "      <th>message to examine</th>\n",
              "      <th>label (depression result)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>106</td>\n",
              "      <td>just had a real good moment. i missssssssss hi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>217</td>\n",
              "      <td>is reading manga  http://plurk.com/p/mzp1e</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>220</td>\n",
              "      <td>@comeagainjen http://twitpic.com/2y2lx - http:...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>288</td>\n",
              "      <td>@lapcat Need to send 'em to my accountant tomo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>540</td>\n",
              "      <td>ADD ME ON MYSPACE!!!  myspace.com/LookThunder</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10309</th>\n",
              "      <td>802309</td>\n",
              "      <td>No Depression by G Herbo is my mood from now o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10310</th>\n",
              "      <td>802310</td>\n",
              "      <td>What do you do when depression succumbs the br...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10311</th>\n",
              "      <td>802311</td>\n",
              "      <td>Ketamine Nasal Spray Shows Promise Against Dep...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10312</th>\n",
              "      <td>802312</td>\n",
              "      <td>dont mistake a bad day with depression! everyo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10313</th>\n",
              "      <td>802313</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10314 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27c60ee8-6997-4b48-99a2-97c2137b4249')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-27c60ee8-6997-4b48-99a2-97c2137b4249 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-27c60ee8-6997-4b48-99a2-97c2137b4249');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns=['idx','text','label']\n",
        "N=list(range(len(data)))\n",
        "random.seed(2023)\n",
        "random.shuffle(N)\n",
        "data=data.iloc[N[0:5000]]\n",
        "class_names=['not depressed','depressed']"
      ],
      "metadata": {
        "id": "2WNp_-kFLzv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(data, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "cGR-E6ZkNNQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "295d155ab8894ee4935db8fc8faa0af1",
            "6fa7b065d05248d399a9d8d41ec27457",
            "52f00db720c9442d878150a577d156d6",
            "291f006d4df343908bae50ffc00ce933",
            "e0b1c542376b461f94f2f519c2286730",
            "d545192a3fe349b096caa94e9db1cc1f",
            "897fda141a004332851330e5eb2bf4fc",
            "2c739e3dd8384625875e195c7da85f55",
            "618ec3af54fc435bb1b40beb298c9e0d",
            "7996bf9809124ea7a25bfe295651de2c",
            "ffad9bd2f7bb4a9a8a506fddb7377529",
            "fe0ac8369fea42d4afc8cbe171251f8d",
            "2e18f556ebd843cdbb4ed4d655f77b14",
            "bda1ffa3277449b6a3aa09a32c035b10",
            "e5311e4a617f472ab8e64b79f3419c9d",
            "23fc794c6fd3450d8d1d4034fdb14ace",
            "46f7e823aa81473ca06c0f67066cde0f",
            "66542b381eb14e5996f9ad560cb14179",
            "fbc86fef959545b4b620480f7fd2b69e",
            "fe7f7ce50785477b9f25c52ff9b6a7ca",
            "ab3a034d136649df8b5d35556d65cf23",
            "211e755a40a54adab8261a79ee970ceb",
            "da64abc61e12437bbf0c45892060a9ce",
            "f13280d8ed7345db90fc8a9485355e76",
            "d520b1f6f1fd4394ac8e9962a559f859",
            "2928320b745f4cdb8d65abf6b2dcbbc4",
            "349cbf4b644a4e37a0ba87660a785fa4",
            "e3608cf560ab4f9c9d98c5960d1f07d2",
            "4e82268e7be1458d9213c832a75a4512",
            "fa7c4e675c1942f494fa623d8cc91918",
            "de75ada89e024221a9e59a8c24ca5a8d",
            "0ebb3958724d4025bcfaf025b444937c",
            "f57435ebaad0473096267f32e436dce3"
          ]
        },
        "id": "2OeNLyXuNSm9",
        "outputId": "d1f28e55-987f-4097-d378-9e5063c5940a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "295d155ab8894ee4935db8fc8faa0af1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe0ac8369fea42d4afc8cbe171251f8d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da64abc61e12437bbf0c45892060a9ce"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#result of one sentence\n",
        "test_s = train[\"text\"].iloc[0]\n",
        "print(test_s)\n",
        "print()\n",
        "result1 = tokenizer.encode_plus(test_s)\n",
        "print(result1)\n",
        "print()\n",
        "print(tokenizer.decode(result1[\"input_ids\"]))\n",
        "print()\n",
        "len(test_s.split(\" \"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbDJFzB5NXsO",
        "outputId": "fc28961c-9a15-4687-d30d-76aea15b5890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@jaychasm i wish i was there with you niggies! gnite luv! \n",
            "\n",
            "{'input_ids': [101, 1030, 6108, 7507, 6491, 1045, 4299, 1045, 2001, 2045, 2007, 2017, 9152, 13871, 3111, 999, 1043, 3490, 2618, 11320, 2615, 999, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "\n",
            "[CLS] @ jaychasm i wish i was there with you niggies! gnite luv! [SEP]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_sens = 16\n",
        "\n",
        "train = train.sort_values('label').reset_index(drop=True)\n",
        "train[\"kfold\"] = train.index % 5\n",
        "p_train = train[train[\"kfold\"]!=0].reset_index(drop=True)#1,2,3,4\n",
        "p_valid = train[train[\"kfold\"]==0].reset_index(drop=True)#0"
      ],
      "metadata": {
        "id": "FqJludKgNbIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_test = test.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "tVxQPRhLNeVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTDataSet(Dataset):\n",
        "\n",
        "    def __init__(self,sentences,targets):\n",
        "        self.sentences = sentences\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        sentence = self.sentences[idx]\n",
        "        bert_sens = tokenizer.encode_plus(\n",
        "                                sentence,\n",
        "                                add_special_tokens = True,\n",
        "                                max_length = max_sens,\n",
        "                                pad_to_max_length = True,\n",
        "                                return_attention_mask = True)\n",
        "\n",
        "        ids = torch.tensor(bert_sens['input_ids'], dtype=torch.long)\n",
        "        mask = torch.tensor(bert_sens['attention_mask'], dtype=torch.long)\n",
        "        token_type_ids = torch.tensor(bert_sens['token_type_ids'], dtype=torch.long)\n",
        "        target = torch.tensor(self.targets[idx],dtype=torch.float)\n",
        "\n",
        "        return {\n",
        "                'ids': ids,\n",
        "                'mask': mask,\n",
        "                'token_type_ids': token_type_ids,\n",
        "                'targets': target\n",
        "            }"
      ],
      "metadata": {
        "id": "wqtn4q1vNhDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = BERTDataSet(p_train[\"text\"],p_train['label'])\n",
        "valid_dataset = BERTDataSet(p_valid[\"text\"],p_valid['label'])\n",
        "\n",
        "batch = 16\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset,batch_size=batch,shuffle = True,num_workers=8,pin_memory=True)\n",
        "valid_dataloader = DataLoader(valid_dataset,batch_size=batch,shuffle = False,num_workers=8,pin_memory=True)"
      ],
      "metadata": {
        "id": "p1Lc7f2HNmyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = BERTDataSet(p_test[\"text\"],p_test['label'])\n",
        "test_dataloader = DataLoader(test_dataset,batch_size=batch,shuffle = False,num_workers=8,pin_memory=True)"
      ],
      "metadata": {
        "id": "W4e8KNrWNqDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = transformers.BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels=1)\n",
        "#model = transformers.BertForSequenceClassification.from_pretrained(\"../input/bert-base-uncased\",num_labels=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "48144e0a6e474c54b20ad047771c0c04",
            "718b958f9d064f5eadcacc70fcb910ec",
            "2e3e424819df4a9bb36371de16d60e07",
            "da5f103e694746cb8eb00fb47dc11fd1",
            "2f52acc35a2f4903ae142d300f260a3e",
            "915450a7ff924aae8c3ac34d6aa8ba99",
            "8e1b74969658490faed6238acd740335",
            "fb641373276c4e8e88d93973ab91893c",
            "189eb38b743845cf85adbe4acc9f397d",
            "423b96cdd138492ebec9ea71cd4fd99f",
            "5e8a2acfd68c43e78af50eefe418d850"
          ]
        },
        "id": "CcCxijrHNssS",
        "outputId": "1289f901-bdea-4327-8d66-95792cdbd205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48144e0a6e474c54b20ad047771c0c04"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "model.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8yzZPF2Nwnu",
        "outputId": "827bdfa3-ca21-491b-d126-d017437ad040"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for item in train_dataloader:\n",
        "    ids = item[\"ids\"].to(device)\n",
        "    mask = item[\"mask\"].to(device)\n",
        "    #tokentype = a[\"token_type_ids\"].to(device)\n",
        "    output = model(ids,mask)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvk0l5B2N2nr",
        "outputId": "7d8fa2a9-021f-4d19-a7b8-861209ccce3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = output[\"logits\"].squeeze(-1).shape"
      ],
      "metadata": {
        "id": "3xnXcMzyN5iV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW\n",
        "LR=2e-5\n",
        "optimizer = AdamW(model.parameters(), LR,betas=(0.9, 0.999), weight_decay=1e-2)"
      ],
      "metadata": {
        "id": "zhLN8oZ1N-Cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs = 20\n",
        "if debug:\n",
        "    epochs = 1\n",
        "train_steps = int(len(p_train)/batch*epochs)\n",
        "print(train_steps)\n",
        "num_steps = int(train_steps*0.1)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d6Oq1Y3OAn1",
        "outputId": "25c34da3-dae4-4a4b-b8db-e733fee43dc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(output,target):\n",
        "    return torch.sqrt(nn.MSELoss()(output,target))"
      ],
      "metadata": {
        "id": "tFtfTnJEOE4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training(\n",
        "    train_dataloader,\n",
        "    model,\n",
        "    optimizer,\n",
        "    scheduler\n",
        "):\n",
        "\n",
        "    model.train()\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    allpreds = []\n",
        "    alltargets = []\n",
        "\n",
        "    for a in train_dataloader:\n",
        "        losses = []\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            ids = a[\"ids\"].to(device,non_blocking=True)\n",
        "            mask = a[\"mask\"].to(device,non_blocking=True)\n",
        "            tokentype = a[\"token_type_ids\"].to(device,non_blocking=True)\n",
        "            output = model(ids,mask)\n",
        "            output = output[\"logits\"].squeeze(-1)\n",
        "            target = a[\"targets\"].to(device,non_blocking=True)\n",
        "            loss = loss_fn(output,target)\n",
        "            losses.append(loss.item())\n",
        "            allpreds.append(output.detach().cpu().numpy())\n",
        "            alltargets.append(target.detach().squeeze(-1).cpu().numpy())\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        del loss\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    allpreds = np.concatenate(allpreds)\n",
        "    alltargets = np.concatenate(alltargets)\n",
        "    losses = np.mean(losses)\n",
        "    # Score with rmse\n",
        "    train_rme_loss = np.sqrt(mean_squared_error(alltargets,allpreds))\n",
        "\n",
        "    return losses,train_rme_loss\n"
      ],
      "metadata": {
        "id": "Td9lkqR5OF2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validating(\n",
        "    valid_dataloader,\n",
        "    model\n",
        "):\n",
        "\n",
        "    model.eval()\n",
        "    allpreds = []\n",
        "    alltargets = []\n",
        "\n",
        "    for a in valid_dataloader:\n",
        "        losses = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            ids = a[\"ids\"].to(device)\n",
        "            mask = a[\"mask\"].to(device)\n",
        "            tokentype = a[\"token_type_ids\"].to(device)\n",
        "            output = model(ids,mask)\n",
        "            output = output[\"logits\"].squeeze(-1)\n",
        "            target = a[\"targets\"].to(device)\n",
        "            loss = loss_fn(output,target)\n",
        "            losses.append(loss.item())\n",
        "            allpreds.append(output.detach().cpu().numpy())\n",
        "            alltargets.append(target.detach().squeeze(-1).cpu().numpy())\n",
        "\n",
        "            del loss\n",
        "\n",
        "    allpreds = np.concatenate(allpreds)\n",
        "    alltargets = np.concatenate(alltargets)\n",
        "    losses = np.mean(losses)\n",
        "    valid_rme_loss = np.sqrt(mean_squared_error(alltargets,allpreds))\n",
        "\n",
        "    return allpreds,losses,valid_rme_loss\n"
      ],
      "metadata": {
        "id": "_FYcM4PbOMPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if debug2 == False:\n",
        "    for a in range(epochs):\n",
        "        for b in train_dataloader:\n",
        "            break\n",
        "    losses,train_rme_loss = training(train_dataloader,model,optimizer,scheduler)\n",
        "\n",
        "    for a in valid_dataloader:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjOZukUQORbM",
        "outputId": "54da0004-3124-4744-b6bd-612bb874d62d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initializing the data\n",
        "p_train = train[train[\"kfold\"]!=0].reset_index(drop=True)\n",
        "p_valid = train[train[\"kfold\"]==0].reset_index(drop=True)\n",
        "\n",
        "train_dataset = BERTDataSet(p_train[\"text\"],p_train['label'])\n",
        "valid_dataset = BERTDataSet(p_valid[\"text\"],p_valid['label'])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset,batch_size=batch,shuffle = True,num_workers=4,pin_memory=True)\n",
        "valid_dataloader = DataLoader(valid_dataset,batch_size=batch,shuffle = False,num_workers=4,pin_memory=True)\n",
        "\n",
        "model = transformers.BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels=1)\n",
        "\n",
        "model.to(device)\n",
        "LR=2e-5\n",
        "optimizer = AdamW(model.parameters(), LR,betas=(0.9, 0.999), weight_decay=1e-2) # AdamW optimizer\n",
        "\n",
        "train_steps = int(len(p_train)/batch*epochs)\n",
        "\n",
        "num_steps = int(train_steps*0.1)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVQTAZUTOWu3",
        "outputId": "22ad6eac-4028-4dd6-af4b-d0bd0d882c99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainlosses = []\n",
        "vallosses = []\n",
        "bestscore = None\n",
        "\n",
        "trainscores = []\n",
        "validscores = []\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    print()\n",
        "    print(\"epoch \" + str(epoch) + \" start -------------\")\n",
        "\n",
        "    trainloss,trainscore = training(train_dataloader,model,optimizer,scheduler)\n",
        "\n",
        "    trainlosses.append(trainloss)\n",
        "    trainscores.append(trainscore)\n",
        "\n",
        "    print(\"trainscore is \" + str(trainscore))\n",
        "\n",
        "    preds,validloss,valscore=validating(valid_dataloader,model)\n",
        "\n",
        "    vallosses.append(validloss)\n",
        "    validscores.append(valscore)\n",
        "\n",
        "    print(\"valscore is \" + str(valscore))\n",
        "\n",
        "    if bestscore is None:\n",
        "        bestscore = valscore\n",
        "\n",
        "        print(\"Save first model\")\n",
        "\n",
        "        state = {\n",
        "                        'state_dict': model.state_dict(),\n",
        "                        'optimizer_dict': optimizer.state_dict(),\n",
        "                        \"bestscore\":bestscore\n",
        "                    }\n",
        "\n",
        "        torch.save(state, \"model0.pth\")\n",
        "\n",
        "    elif bestscore > valscore:\n",
        "\n",
        "        bestscore = valscore\n",
        "        print(\"found better point\")\n",
        "        state = {\n",
        "                        'state_dict': model.state_dict(),\n",
        "                        'optimizer_dict': optimizer.state_dict(),\n",
        "                        \"bestscore\":bestscore\n",
        "                    }\n",
        "\n",
        "        torch.save(state, \"model0.pth\")\n",
        "\n",
        "    else:\n",
        "        pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSHuvHBlOfTf",
        "outputId": "42534525-b227-4148-b912-85ef3fda7290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch 0 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.37897253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.25726268\n",
            "Save first model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 1/20 [00:25<07:58, 25.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch 1 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.25055024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.2255187\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [00:51<07:45, 25.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch 2 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.1940196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 15%|█▌        | 3/20 [01:08<06:07, 21.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.23827095\n",
            "\n",
            "epoch 3 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.1394403\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.21817394\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 4/20 [01:30<05:50, 21.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch 4 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.10955025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 25%|██▌       | 5/20 [01:46<04:57, 19.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.23177733\n",
            "\n",
            "epoch 5 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.08576672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 30%|███       | 6/20 [02:02<04:20, 18.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.220618\n",
            "\n",
            "epoch 6 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.08128818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.21402222\n",
            "found better point\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 7/20 [02:24<04:16, 19.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch 7 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.069522895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 40%|████      | 8/20 [02:40<03:42, 18.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.21644913\n",
            "\n",
            "epoch 8 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.06723477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 45%|████▌     | 9/20 [02:56<03:15, 17.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.2214848\n",
            "\n",
            "epoch 9 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.05587906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 50%|█████     | 10/20 [03:14<02:57, 17.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.22790875\n",
            "\n",
            "epoch 10 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.051351584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 55%|█████▌    | 11/20 [03:31<02:36, 17.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.21919367\n",
            "\n",
            "epoch 11 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.04793497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 60%|██████    | 12/20 [03:47<02:17, 17.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.2222008\n",
            "\n",
            "epoch 12 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.047340497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 65%|██████▌   | 13/20 [04:04<01:58, 16.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.22223882\n",
            "\n",
            "epoch 13 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.047047414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 70%|███████   | 14/20 [04:20<01:40, 16.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.21987103\n",
            "\n",
            "epoch 14 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.046917893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 75%|███████▌  | 15/20 [04:36<01:23, 16.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.22047736\n",
            "\n",
            "epoch 15 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.04674241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 80%|████████  | 16/20 [04:53<01:07, 16.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.2237416\n",
            "\n",
            "epoch 16 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.04644625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 85%|████████▌ | 17/20 [05:10<00:49, 16.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.22258459\n",
            "\n",
            "epoch 17 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.04546745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 90%|█████████ | 18/20 [05:26<00:32, 16.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.21936432\n",
            "\n",
            "epoch 18 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.043234196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            " 95%|█████████▌| 19/20 [05:42<00:16, 16.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.22016391\n",
            "\n",
            "epoch 19 start -------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainscore is 0.0425671\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "100%|██████████| 20/20 [05:58<00:00, 17.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valscore is 0.22022969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(p_valid['label'],preds, alpha=0.2)\n",
        "plt.title('Validation Prediction Result')\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Prediction')\n",
        "plt.show()\n",
        "\n",
        "x = np.arange(epochs)\n",
        "plt.title('Validation Losses')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(x,trainlosses)\n",
        "plt.plot(x,vallosses)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "wK_FhJYOOl16",
        "outputId": "db3b031f-fac5-4103-fb9b-3717d51a3dc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.arange(epochs)\n",
        "plt.title('Validation Scores')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Score')\n",
        "plt.plot(x,trainscores)\n",
        "plt.plot(x,validscores)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "R0fB8IqnOo5J",
        "outputId": "ab565f32-d156-40a6-ef6a-7a4a486e825b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names=['Not Real','Real']"
      ],
      "metadata": {
        "id": "oCdoLhUpOsUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_true = p_valid['label']\n",
        "val_pred = []\n",
        "for p in preds:\n",
        "    val_pred+=[np.where(p<0.5,0,1).item()]"
      ],
      "metadata": {
        "id": "KNjyqk6eOvHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(val_true,val_pred,target_names=class_names,digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEMbXOVdOx6y",
        "outputId": "46ecead6-c647-4eb3-acbd-d222aedcf50c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Not Real     0.9575    0.9775    0.9674       622\n",
            "        Real     0.9152    0.8483    0.8805       178\n",
            "\n",
            "    accuracy                         0.9487       800\n",
            "   macro avg     0.9363    0.9129    0.9239       800\n",
            "weighted avg     0.9481    0.9487    0.9480       800\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predicting(test_dataloader,model,):\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    allpreds = []\n",
        "    preds = []\n",
        "    allvalloss=0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for a in test_dataloader:\n",
        "\n",
        "            ids = a[\"ids\"].to(device)\n",
        "            mask = a[\"mask\"].to(device)\n",
        "            tokentype = a[\"token_type_ids\"].to(device)\n",
        "\n",
        "           # output = model(ids,mask,tokentype)\n",
        "            output = model(ids,mask)\n",
        "            output = output[\"logits\"].squeeze(-1)\n",
        "            preds.append(output.cpu().numpy())\n",
        "\n",
        "        preds = np.concatenate(preds)\n",
        "        allpreds.append(preds)\n",
        "\n",
        "    return allpreds\n"
      ],
      "metadata": {
        "id": "xacoZWwwO0o8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tpreds = predicting(test_dataloader,model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJwYmkCLO5YO",
        "outputId": "e3705094-68d8-43c7-cc93-a8a17a5625ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_true = p_test['label']\n",
        "test_pred = []\n",
        "for p in tpreds[0]:\n",
        "    test_pred+=[np.where(p<0.5,0,1).item()]\n",
        "\n",
        "#tpred_df = pd.DataFrame(tpreds)\n",
        "#tpred_dfT = tpred_df.T\n",
        "#test_pred = tpred_dfT.mean(axis=1)"
      ],
      "metadata": {
        "id": "ayyyym_9O8Jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test_true,test_pred,target_names=class_names,digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkK_vz9KPBLw",
        "outputId": "4874fd61-8cc6-43d8-9a01-1a1c360f00fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Not Real     0.9408    0.9845    0.9622       775\n",
            "        Real     0.9365    0.7867    0.8551       225\n",
            "\n",
            "    accuracy                         0.9400      1000\n",
            "   macro avg     0.9387    0.8856    0.9086      1000\n",
            "weighted avg     0.9398    0.9400    0.9381      1000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}